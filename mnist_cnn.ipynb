{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0ulQR1m6YRo1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import wandb\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "import multiprocessing\n",
        "import platform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 함수 정의\n",
        "def get_num_cpu_cores():\n",
        "    \"\"\"시스템의 CPU 코어 수 반환\"\"\"\n",
        "    return multiprocessing.cpu_count()\n",
        "\n",
        "def is_linux():\n",
        "    \"\"\"현재 OS가 리눅스인지 확인\"\"\"\n",
        "    return platform.system().lower() == \"linux\"\n",
        "\n",
        "def is_windows():\n",
        "    \"\"\"현재 OS가 윈도우인지 확인\"\"\"\n",
        "    return platform.system().lower() == \"windows\"\n",
        "\n",
        "# 현재 경로 설정\n",
        "BASE_PATH = str(Path(os.getcwd()).resolve())  # 현재 작업 디렉토리를 BASE_PATH로 설정\n",
        "print(\"BASE_PATH:\", BASE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY-NpNm6a0uW",
        "outputId": "ebf37d86-791d-49e4-f7d8-b42ab859b573"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASE_PATH: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean과 Std 계산 함수\n",
        "def calculate_mean_std(data_loader):\n",
        "    \"\"\"\n",
        "    전체 데이터셋의 Mean과 Std를 계산하는 함수\n",
        "    \"\"\"\n",
        "    mean = 0.0\n",
        "    std = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    # 데이터셋을 순회하며 Mean과 Std 계산\n",
        "    for images, _ in data_loader:\n",
        "        # 배치 크기 확인\n",
        "        batch_samples = images.size(0)\n",
        "        total_samples += batch_samples\n",
        "\n",
        "        # (B, C, H, W) 형태에서 (B, C*H*W)로 펼치기\n",
        "        images = images.view(batch_samples, images.size(1), -1)\n",
        "\n",
        "        # 각 채널에 대해 평균과 표준편차 계산\n",
        "        mean += images.mean([0, 2]).sum(0)\n",
        "        std += images.std([0, 2]).sum(0)\n",
        "\n",
        "    # 총 샘플 수로 나누어 최종 평균 및 표준편차 계산\n",
        "    mean /= total_samples\n",
        "    std /= total_samples\n",
        "\n",
        "    return mean, std"
      ],
      "metadata": {
        "id": "8_EBX8Kwd-HY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean과 Std 계산 함수\n",
        "def calculate_mean_std(data_loader):\n",
        "    \"\"\"\n",
        "    전체 데이터셋의 Mean과 Std를 계산하는 함수\n",
        "    \"\"\"\n",
        "    mean = 0.0\n",
        "    std = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    # 데이터셋을 순회하며 Mean과 Std 계산\n",
        "    for images, _ in data_loader:\n",
        "        # 배치 크기 확인\n",
        "        batch_samples = images.size(0)\n",
        "        total_samples += batch_samples\n",
        "\n",
        "        # (B, C, H, W) 형태에서 (B, C*H*W)로 펼치기\n",
        "        images = images.view(batch_samples, images.size(1), -1)\n",
        "\n",
        "        # 각 채널에 대해 평균과 표준편차 계산\n",
        "        mean += images.mean([0, 2]).sum(0)\n",
        "        std += images.std([0, 2]).sum(0)\n",
        "\n",
        "    # 총 샘플 수로 나누어 최종 평균 및 표준편차 계산\n",
        "    mean /= total_samples\n",
        "    std /= total_samples\n",
        "\n",
        "    return mean, std"
      ],
      "metadata": {
        "id": "aXFMhyONeiS2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fashion MNIST 데이터셋 로드 (학습 및 검증)\n",
        "def get_fashion_mnist_data():\n",
        "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
        "\n",
        "    # Fashion MNIST 데이터 로드\n",
        "    f_mnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
        "    f_mnist_train, f_mnist_validation = random_split(f_mnist_train, [55_000, 5_000])\n",
        "\n",
        "    print(\"Num Train Samples: \", len(f_mnist_train))\n",
        "    print(\"Num Validation Samples: \", len(f_mnist_validation))\n",
        "    print(\"Sample Shape: \", f_mnist_train[0][0].shape)  # torch.Size([1, 28, 28])\n",
        "\n",
        "    # 데이터 로더 생성\n",
        "    train_data_loader = DataLoader(\n",
        "        dataset=f_mnist_train, batch_size=wandb.config.batch_size, shuffle=True, pin_memory=True, num_workers=get_num_cpu_cores()\n",
        "    )\n",
        "\n",
        "    validation_data_loader = DataLoader(\n",
        "        dataset=f_mnist_validation, batch_size=wandb.config.batch_size, pin_memory=True, num_workers=get_num_cpu_cores()\n",
        "    )\n",
        "\n",
        "    # Mean과 Std 계산\n",
        "    mean, std = calculate_mean_std(train_data_loader)\n",
        "    print(f\"Dataset Mean: {mean}, Std: {std}\")\n",
        "\n",
        "    # 데이터 정규화를 위한 변환 정의\n",
        "    f_mnist_transforms = nn.Sequential(\n",
        "        transforms.ConvertImageDtype(torch.float),\n",
        "        transforms.Normalize(mean=mean.tolist(), std=std.tolist()),  # 계산된 Mean과 Std 사용\n",
        "    )\n",
        "\n",
        "    return train_data_loader, validation_data_loader, f_mnist_transforms, mean, std"
      ],
      "metadata": {
        "id": "ey2tqVoper_T"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fashion MNIST 데이터셋 로드 (테스트)\n",
        "def get_fashion_mnist_test_data(mean, std):\n",
        "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
        "\n",
        "    f_mnist_test_images = datasets.FashionMNIST(data_path, train=False, download=True)\n",
        "    f_mnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "    print(\"Num Test Samples: \", len(f_mnist_test))\n",
        "    print(\"Sample Shape: \", f_mnist_test[0][0].shape)  # torch.Size([1, 28, 28])\n",
        "\n",
        "    # 데이터 로더 생성\n",
        "    test_data_loader = DataLoader(dataset=f_mnist_test, batch_size=64, pin_memory=True, num_workers=get_num_cpu_cores())\n",
        "\n",
        "    # 테스트 데이터 정규화를 위한 변환 정의\n",
        "    f_mnist_transforms = nn.Sequential(\n",
        "        transforms.ConvertImageDtype(torch.float),\n",
        "        transforms.Normalize(mean=mean.tolist(), std=std.tolist()),  # 학습 데이터의 Mean과 Std 사용\n",
        "    )\n",
        "\n",
        "    return f_mnist_test_images, test_data_loader, f_mnist_transforms"
      ],
      "metadata": {
        "id": "wFz1iCwYet1h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "\n",
        "# API Key 수동 설정 (선택 사항)\n",
        "os.environ[\"WANDB_API_KEY\"] = \"e4b00d9b8180a4d284aef5d6cf9ac7be13501e1e\"\n",
        "\n",
        "# WandB 로그인\n",
        "wandb.login(relogin=True)\n",
        "\n",
        "# WandB 초기화\n",
        "wandb.init(\n",
        "    project=\"fashion_mnist_project\",\n",
        "    config={\n",
        "        \"batch_size\": 2048,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"epochs\": 10\n",
        "    }\n",
        ")\n",
        "\n",
        "train_data_loader, validation_data_loader, f_mnist_transforms, mean, std = get_fashion_mnist_data()\n",
        "print()\n",
        "f_mnist_test_images, test_data_loader, f_mnist_transforms = get_fashion_mnist_test_data(mean, std)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "n5rBnO3Glxod",
        "outputId": "87e71d3a-bbff-45dc-cc93-7aa7963e538c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:1ixfch42) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">peach-pond-13</strong> at: <a href='https://wandb.ai/dyd877915-korea-university-of-technology-and-education/fashion_mnist_project/runs/1ixfch42' target=\"_blank\">https://wandb.ai/dyd877915-korea-university-of-technology-and-education/fashion_mnist_project/runs/1ixfch42</a><br/> View project at: <a href='https://wandb.ai/dyd877915-korea-university-of-technology-and-education/fashion_mnist_project' target=\"_blank\">https://wandb.ai/dyd877915-korea-university-of-technology-and-education/fashion_mnist_project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241121_075912-1ixfch42/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:1ixfch42). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241121_075937-fnkj6c5a</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dyd877915-korea-university-of-technology-and-education/fashion_mnist_project/runs/fnkj6c5a' target=\"_blank\">trim-water-14</a></strong> to <a href='https://wandb.ai/dyd877915-korea-university-of-technology-and-education/fashion_mnist_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dyd877915-korea-university-of-technology-and-education/fashion_mnist_project' target=\"_blank\">https://wandb.ai/dyd877915-korea-university-of-technology-and-education/fashion_mnist_project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dyd877915-korea-university-of-technology-and-education/fashion_mnist_project/runs/fnkj6c5a' target=\"_blank\">https://wandb.ai/dyd877915-korea-university-of-technology-and-education/fashion_mnist_project/runs/fnkj6c5a</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /content/_00_data/j_fashion_mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/_00_data/j_fashion_mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to /content/_00_data/j_fashion_mnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /content/_00_data/j_fashion_mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 201kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/_00_data/j_fashion_mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /content/_00_data/j_fashion_mnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /content/_00_data/j_fashion_mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.71MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/_00_data/j_fashion_mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /content/_00_data/j_fashion_mnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /content/_00_data/j_fashion_mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 5.73MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/_00_data/j_fashion_mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /content/_00_data/j_fashion_mnist/FashionMNIST/raw\n",
            "\n",
            "Num Train Samples:  55000\n",
            "Num Validation Samples:  5000\n",
            "Sample Shape:  torch.Size([1, 28, 28])\n",
            "Dataset Mean: 0.00014048324374016374, Std: 0.00017339707119390368\n",
            "\n",
            "Num Test Samples:  10000\n",
            "Sample Shape:  torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "py-wbrlgvCI6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CNN 모델 정의\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 장치 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 모델, 손실 함수 및 옵티마이저 초기화\n",
        "model = CNNModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)"
      ],
      "metadata": {
        "id": "-WoJRe2VvL0K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 모델 학습 코드 (WandB 설정값 사용)\n",
        "for epoch in range(wandb.config.epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_data_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # 옵티마이저 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파 및 손실 계산\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 통계 업데이트\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # 에포크별 결과 WandB 로그 기록\n",
        "    train_loss /= len(train_data_loader.dataset)\n",
        "    train_accuracy = 100.0 * correct / total\n",
        "    wandb.log({\"epoch\": epoch + 1, \"train_loss\": train_loss, \"train_accuracy\": train_accuracy})\n",
        "    print(f\"Epoch {epoch+1}/{wandb.config.epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHhB-RvRvnOv",
        "outputId": "607373d3-ed7b-4da5-d334-1362bc4b1b28"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.1898, Accuracy: 61.96%\n",
            "Epoch 2/10, Loss: 0.6092, Accuracy: 77.54%\n",
            "Epoch 3/10, Loss: 0.5117, Accuracy: 81.28%\n",
            "Epoch 4/10, Loss: 0.4562, Accuracy: 83.69%\n",
            "Epoch 5/10, Loss: 0.4223, Accuracy: 84.87%\n",
            "Epoch 6/10, Loss: 0.3962, Accuracy: 85.80%\n",
            "Epoch 7/10, Loss: 0.3744, Accuracy: 86.69%\n",
            "Epoch 8/10, Loss: 0.3594, Accuracy: 87.23%\n",
            "Epoch 9/10, Loss: 0.3446, Accuracy: 87.70%\n",
            "Epoch 10/10, Loss: 0.3326, Accuracy: 88.22%\n"
          ]
        }
      ]
    }
  ]
}